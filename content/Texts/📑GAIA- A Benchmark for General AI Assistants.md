---
created: 2023-12-08
modified: 2024-08-03
tags:
  - 📑
  - 🏗️
aliases: 
parents: 
author: Gr´egoire Mialon, Cl´ementine Fourrier, Craig Swift, Thomas Wolf, Yann LeCun, ThomasScialom
---
LLMの性能を表すベンチマークとして考案された問題集。  
General AI Asistantsから「GAIA」と名付けられたらしい。

人間が解決できないような専門的タスクを解かせるのではなく、**人間は楽に解決できるけどAIは解決できないタスク**を解かせることに着目している。  
研究によれば、この問題の人間の正答率は92%だが、GPT-4の正答率は15%だったらしい。
## 概要

## 参考
- [2311.12983.pdf](https://arxiv.org/pdf/2311.12983.pdf?)
- [[2311.12983] GAIA: a benchmark for General AI Assistants](https://arxiv.org/abs/2311.12983)