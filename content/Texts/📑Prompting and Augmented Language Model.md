---
created: 2024-01-05
modified: 2024-07-30
tags:
  - 📑
aliases: 
parents: "[[📑Overview of Large Language Models]]"
---
学習済みのLLMを追加学習せずに活用する技術について学ぶ。

## 覚えること
- プロンプティングとは何か？
- 文脈内学習とは何か？
- プロンプトにより性能を改善する方法
- Augmented Language Modelの必要性と原理

## 言語モデルによるタスク実行
### QA（Quality Assurance?）
候補の中で生成確率が最大のものを探す。
![[QA.png]]
### センチメント分析
テキスト情報から感情を分析する。（同じく生成確率が最大のもの）
![[センチメント分析.png]]

ところが、「日本の首都は」の次に必ず「東京」が続くとは限らない。以下はその例である。

- **日本の首都は**どこですか？
- **日本の首都は**京都ではない
- 平安時代の**日本の首都は**平安京

よりうまく入力/条件を与えることで性能を高めることはできないか？

# プロンプティング(Prompting)
特定の機能の発生を促進させるように、言語モデルに入力するコンテキスト文。
言語モデルへの入力を工夫することで性能が改善する。
![[zero-shot.png]]

## 文脈内学習(In-Context Learning)
特にモデルが大規模な場合、Few-Shotのデモンストレーションを追加することで性能が上がることが多い。
![[few-shot.png]]

これは文脈内から学習するため、文脈内学習(In-Context Learning)と呼ばれる。
![[In-Context Learning.png]]

## Fine-Tuningと文脈内学習
従来のFine-Tuningは事例によってモデルのパラメータを更新して予測を修正する。
- 性能が出やすい
- 毎回事例を入れなくてもよい
- タスクごとにモデルが変わる
- 学習コストがかかる

文脈内学習はパラメータを更新せず、条件付けによって予測を修正する。
- すべてのタスクで単一のモデルが使える
- 学習コストがかからない
- Fine-Tuningよりは性能が出やすい
- 推論コストが高い

## Chain-of-Thought (CoT) Prompting
![[Chain of Thought.png]]

Few-Shotの事例の際に思考過程を入れると、新しい質問についても思考過程を明示してくれる。  
こちらもモデルサイズが大きい場合に性能の改善が大きい。

### Self Consistency
![[Self Consistency.png]]

LLMに複数の推論を行わせて、多数決で答えを決める。  
もっともらしい確率の高いものが、必ずしも正しい推論とは限らない。

### Zero-Shot Chain-of-Thought
*「Let's think step by step.」という文を加えると性能が上がる*、という言説の根拠。推論に多くの段階が必要なタスクに適している。
逆に1回の推論で十分なタスクに使ってしまうと、考えすぎて失敗する場合がある。

## Tree of Thoughts
![[Tree of Thoughts.png]]

単独の推論を途中で分岐させて木検索を行う。各ノードの評価も言語モデルで行う。
Self Consistencyのように複数の思考を並行して評価するのではない。
戦略的思考が必要なタスクで効果があるらしい。

## 発展的なプロンプト
[敵対的プロンプト（Adversarial Prompting） | Prompt Engineering Guide](https://www.promptingguide.ai/jp/risks/adversarial)
### 敵対的プロンプティング
ジェイルブレイク（DAN - Do Anything Now）が有名。これは吉永さんが去年教えてくれた。

### プロンプトインジェクション
タスクにプロンプトを突っ込んで意図しない挙動を引き起こす。いわゆるSQLインジェクションのLLMバージョン。

なお、SaySayAI鯖のBotには「プロンプトインジェクションに負けないおじさん」がいる。文字通り、プロンプトインジェクションに対してバチバチに対策したおじさんである。  
そんなおじさんでも、ごく稀にインジェクションが当たって機密情報を漏らすことがある。ハッカーの執念（というか遊び心）には恐れ入る。

### プロンプトリーク

### 行動系列の生成（松尾研での研究例）
自然言語による命令を、たとえばロボットが認識できるJSON形式に変換する。  
これが発展すれば、口頭で一言命令するだけで一連のタスクをこなすロボットが作れるかもしれない。

### マルチモーダルプロンプト
画像と文章、動画と文章など複数の形式が組み合わさったプロンプト。  
画像読取モデルと言語モデルといった、複数モデルを統合させたモデルを使う。

## 文脈内学習における謎
文脈内学習によってモデルの精度が上がることはわかった。  
しかし、**何を** **どうやって** 学習しているのだろうか？

### どうやって？
- メタ勾配を計算して暗黙的にパラメータを更新している？
### 何を？
- 入出力関係以外の要素を学習している？
	- フォーマット、入力分布、ラベル空間、etc...
- 新しい知識を学んでいるかは疑問
	- 出題頻度と精度に強い相関が見られる
- 大規模モデルは入出力関係も学習しているらしい

どのようにしたら良いプロンプトを設計できるのか？  
LLMは文脈から何をどう学んでいるのか？  
これらについては不明瞭な点も多い。

# Augmented Language Models
![[AugmentedLanguageModel.png]]

外部知識やツールとLLMを併用することで、LLM単独では難しいタスクを実行する。

## 外部知識・ツールを使う理由
### 1. 学習効率を高めるため
タスクを解くのに必要な知識や能力は多様だが、LLM単体でタスクを解く場合、そうした知識や能力をすべて内部に保持する必要がある。

しかし大量に保持した結果、単純な足し算の計算ミスが多発する。
それならば、外部知識や外部ツールを使うことで効率よく学習できないか？
### 2. 知識を更新するため
- 知識が誤っていた場合はどう修正すればよいのか？
	- LLMに含まれている知識の修正は大変
- モデルに新しい知識を加えたい場合は？
	- 例：「現在の大谷翔平の本塁打数は？」の回答は、*現在が何年何月何日か*で異なる
### 3. 信頼性を高めるため
LLMは誤った知識をもっともらしく話してしまう、Hallucination（幻覚）問題がある。

### Retrieval Augmented Language Modelの全体像
![[RetrievalAugmentedLMの全体像.png]]

Retrieverの役割は、外部テキストdからクエリqに類似した文章を見つけること。
### 類似度の定義
#### TF-IDF(Term Frequency Inverse Document Frequency)
文書中に含まれる単語の重要度を評価する手法のひとつ。  
TF: 文書中の単語出現頻度 = 単語個数 / 単語総数  
IDF: 文書全体の単語出現頻度 = 単語のある文書数 / 文書総数の逆数  

疎な表現(Bag-of-Words)を用いているためSparse Retrieverと呼ばれる。  
よく使われる亜種に[Okapi BM25](https://ja.wikipedia.org/wiki/Okapi_BM25)がある。
$$sim(d,q)=tf_{d,q} ×\log\frac{N}{df_q}$$
#### 埋め込み(Embedding)のコサイン類似度
密な表現(ニューラルネットワークの埋め込み)を用いているため、Dense Retrieverと呼ばれる。  
$E(d)$は適当なニューラルネットワーク（Sentence BERT、OpenAIのEmbedding API）。
$$sim(d,q)=\cos(E(d),E(q))$$

### Retrieverに求められる要件
1. ある重要なキーワードを含んでいること（例：World Cup）
2. 文章の意味的な類似度を反映していること
一般的にSparse Retrieverは1が、Dense Retrieverは2が得意。

### 検索された文章の使い方
#### コンテキストとして追加
![[Retrieval-Augmented Black Box Langualge Models.png]]

検索した文章を元の入力にくっつけてプロンプトとして入力する。Retrieval Augmented Generation(RAG)とも呼ばれる。
検索結果が複数ある場合は複数個の予測をアンサンブルすることもある。
また、入力ではなく中間層に入れるケースもある。

#### 予測の修正
![[knn-prompt.png]]

外部データベースでの類似文書の生成確率によりLanguage Modelの予測を修正。
センチメント分析で特に大きく改善される。
### Retrieval Augmented LMの補足
- どのデータベースを使うかはタスクによる
	- 研究ではWikiやCreative Commons
	- 特定の知識をつけたい場合は、つけたい知識のDBを作る
- 大量のデータベースから効率的に検索する方法も研究中
- RetrieverやLanguage Modelが学習することもある

## 参考
- プロンプティング
- 文脈内学習
- [Augmented Language Models (LLM Bootcamp) - YouTube](https://www.youtube.com/watch?v=YdeuQhlHmCA)
- [2302.07842.pdf](https://arxiv.org/pdf/2302.07842.pdf)